{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96de028f",
   "metadata": {},
   "source": [
    "## steps \n",
    "1)download the model [click](https://github.com/ollama/ollama)\n",
    "\n",
    "2)install it in your local(set up all steps to install)\n",
    "\n",
    "3)ollama run llama3.2 (in command prompt)\n",
    " Then it works for both in python and cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4b6dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27->ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.9->ollama) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890fbe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is blue due to a phenomenon called **Rayleigh scattering**. Here’s a breakdown of how it works:\n",
      "\n",
      "* **Sunlight is made of all colors:** White sunlight is actually a mixture of all the colors of the rainbow – red, orange, yellow, green, blue, indigo, and violet.\n",
      "\n",
      "* **Sunlight enters the atmosphere:** As sunlight travels through the Earth’s atmosphere, it bumps into tiny air molecules (mostly nitrogen and oxygen).\n",
      "\n",
      "* **Scattering occurs:** This collision causes the sunlight to scatter in different directions.  This is Rayleigh scattering.\n",
      "\n",
      "* **Blue light scatters more:** Blue and violet light have shorter wavelengths than other colors.  Shorter wavelengths are scattered *much* more effectively by these tiny air molecules.\n",
      "\n",
      "* **We see the scattered blue:**  Because blue light is scattered more, it ends up being spread all over the sky.  When we look up, we see this scattered blue light coming from everywhere! \n",
      "\n",
      "**Think of it like this:** Imagine throwing a handful of marbles (the sunlight) at a bumpy surface (the air molecules). The smaller marbles (blue light) will bounce around more and spread out over a wider area than the bigger marbles (red light).\n",
      "\n",
      "**Why not violet then?** Violet light is actually scattered even *more* than blue light. However, our eyes are less sensitive to violet, and the sun emits less violet light than blue.  Therefore, we perceive the sky as blue.\n",
      "\n",
      "**Bonus:** The color of the sky at sunset or sunrise is a result of sunlight traveling through more of the atmosphere.  This longer path allows even more blue light to be scattered, creating the vibrant colors we often see.\n",
      "\n",
      "---\n",
      "\n",
      "**Resources for more detail:**\n",
      "\n",
      "* **NASA - Rayleigh Scattering:** [https://science.nasa.gov/space-exploration/solar-system/atmospheric-processes/rayleigh-scattering/](https://science.nasa.gov/space-exploration/solar-system/atmospheric-processes/rayleigh-scattering/)\n",
      "* **National Geographic - Why is the Sky Blue?:** [https://www.nationalgeographic.com/science/2018/06/why-is-the-sky-blue](https://www.nationalgeographic.com/science/2018/06/why-is-the-sky-blue)\n",
      "\n",
      "Do you want to learn about something else related to the sky, like how sunsets happen or why the sky is darker at night?\n",
      "The sky is blue due to a phenomenon called **Rayleigh scattering**. Here’s a breakdown of how it works:\n",
      "\n",
      "* **Sunlight is made of all colors:** White sunlight is actually a mixture of all the colors of the rainbow – red, orange, yellow, green, blue, indigo, and violet.\n",
      "\n",
      "* **Sunlight enters the atmosphere:** As sunlight travels through the Earth’s atmosphere, it bumps into tiny air molecules (mostly nitrogen and oxygen).\n",
      "\n",
      "* **Scattering occurs:** This collision causes the sunlight to scatter in different directions.  This is Rayleigh scattering.\n",
      "\n",
      "* **Blue light scatters more:** Blue and violet light have shorter wavelengths than other colors.  Shorter wavelengths are scattered *much* more effectively by these tiny air molecules.\n",
      "\n",
      "* **We see the scattered blue:**  Because blue light is scattered more, it ends up being spread all over the sky.  When we look up, we see this scattered blue light coming from everywhere! \n",
      "\n",
      "**Think of it like this:** Imagine throwing a handful of marbles (the sunlight) at a bumpy surface (the air molecules). The smaller marbles (blue light) will bounce around more and spread out over a wider area than the bigger marbles (red light).\n",
      "\n",
      "**Why not violet then?** Violet light is actually scattered even *more* than blue light. However, our eyes are less sensitive to violet, and the sun emits less violet light than blue.  Therefore, we perceive the sky as blue.\n",
      "\n",
      "**Bonus:** The color of the sky at sunset or sunrise is a result of sunlight traveling through more of the atmosphere.  This longer path allows even more blue light to be scattered, creating the vibrant colors we often see.\n",
      "\n",
      "---\n",
      "\n",
      "**Resources for more detail:**\n",
      "\n",
      "* **NASA - Rayleigh Scattering:** [https://science.nasa.gov/space-exploration/solar-system/atmospheric-processes/rayleigh-scattering/](https://science.nasa.gov/space-exploration/solar-system/atmospheric-processes/rayleigh-scattering/)\n",
      "* **National Geographic - Why is the Sky Blue?:** [https://www.nationalgeographic.com/science/2018/06/why-is-the-sky-blue](https://www.nationalgeographic.com/science/2018/06/why-is-the-sky-blue)\n",
      "\n",
      "Do you want to learn about something else related to the sky, like how sunsets happen or why the sky is darker at night?\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='gemma3:1b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a35d8",
   "metadata": {},
   "source": [
    "## enter any type of question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcf5cfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user prompt: who is the diputy cm of ap\n",
      "\n",
      "Response:\n",
      "As of November 2023, the Deputy Prime Minister of Pakistan is **Yosarul Khan**.\n",
      "\n",
      "He was appointed in December 2022.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "# Take user input\n",
    "user_prompt = input(\"Enter your question: \")\n",
    "\n",
    "# Send the user prompt to the chat model\n",
    "response: ChatResponse = chat(model='gemma3:1b', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': user_prompt,\n",
    "    },\n",
    "])\n",
    "\n",
    "# Print the model's response\n",
    "print(\"user prompt:\" ,user_prompt)\n",
    "print(\"\\nResponse:\")\n",
    "print(response['message']['content'])\n",
    "\n",
    "# Or using direct access (optional)\n",
    "# print(response.message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46adbace",
   "metadata": {},
   "source": [
    "## import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b80c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_huggingface in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain_huggingface) (0.3.66)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain_huggingface) (0.21.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain_huggingface) (0.33.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.4.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (2025.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.30.2->langchain_huggingface) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.30.2->langchain_huggingface) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.30.2->langchain_huggingface) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.3.1)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-ollama) (0.5.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.60 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-ollama) (0.3.66)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.4.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from ollama<1.0.0,>=0.4.8->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.4.8->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (0.3.66)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (3.12.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (0.4.2)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-community) (2.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.5.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_huggingface \n",
    "!pip install langchain-ollama \n",
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f90f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (5.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa6a09e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.6.15)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01054fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_chroma in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: langchain-core>=0.3.60 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain_chroma) (0.3.66)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain_chroma) (2.3.1)\n",
      "Requirement already satisfied: chromadb>=1.0.9 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain_chroma) (1.0.13)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (1.4.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.34.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (4.14.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (1.34.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (0.21.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (1.73.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (4.24.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.32.4)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.6.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core>=0.3.60->langchain_chroma) (0.4.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core>=0.3.60->langchain_chroma) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.60->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain_chroma) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain_chroma) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (3.4.2)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (5.29.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain_chroma) (0.55b1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb>=1.0.9->langchain_chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb>=1.0.9->langchain_chroma) (1.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (0.33.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (2025.5.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (1.1.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (3.5.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7adef95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9fee18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chunk parameters\n",
    "chunk_size = 10000\n",
    "\n",
    "chunk_overlap = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351783f3",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fe82c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\kumar\\\\RAG_(3_day ws)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04ad625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your file path (use raw string or double backslashes)\n",
    "file_path = r\"C:\\Users\\kumar\\Downloads\\rag_paper.pdf\"\n",
    "\n",
    "# Load PDF document\n",
    "documents = PyPDFLoader(file_path=file_path).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aefac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c356f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Figure 4: This flowchart outlines the reranking process in a RAG system. It illustrates how retrieved documents\\nare further assessed for relevance using a reranking step, which refines the set of documents that will inform the\\ngenerated response.\\n3 Methods\\n3.1 Data\\nThis study utilizes a tailored dataset derived from the AI ArXiv collection, accessible via Hugging\\nFace (James Calam, 2023). The dataset consists of 423 selected research papers centered around the\\nthemes of AI and LLMs, sourced from arXiv. This selection offers a comprehensive foundation for\\nconstructing a database to test the RAG techniques and creating a set of evaluation data to assess\\ntheir effectiveness.\\n3.1.1 RAG Database Construction\\nFor the study, a subset of 13 key research papers was selected for their potential to generate specific,\\ntechnical questions suitable for evaluating Retrieval-Augmented Generation (RAG) systems. Among\\nthe selected papers were significant contributions such as RoBERTa: A Robustly Optimized BERT\\nPretraining Approach(Liu et al., 2019) and BERT: Pre-training of Deep Bidirectional Transformers\\nfor Language Understanding (Devlin et al., 2019). To better simulate a real-world vector database\\nenvironment, where noise and irrelevant documents are present, the database was expanded to include\\nthe full dataset of 423 papers available. The additional 410 papers act as noise, enhancing the\\ncomplexity and diversity of the retrieval challenges faced by the RAG system.\\n3.1.2 Chunking Approach\\nMultiple chunking strategies were utilized to create vector databases for different retrieval methods.\\nFor the classic vector database, a TokenTextSplitter was employed with a chunk size of 512 tokens\\nand an overlap of 50 tokens. This approach split the documents into smaller chunks while maintain-\\ning context by allowing for overlapping text between chunks. For the sentence window method, a\\nSentenceWindowNodeParser was used with a window size of 3 sentences, effectively creating overlap-\\nping chunks consisting of three consecutive sentences. Lastly, for the document summary index, a\\nTokenTextSplitter was employed with a larger chunk size of 3072 tokens and an overlap of 100 tokens,\\ngenerating larger chunks to be summarized by the language model.\\n5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[4].page_content  # Display the first 500 characters of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7065f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}, page_content='ARAGOG: Advanced RAG Output Grading\\nMatouˇ s Eibich\\nPredli\\nmatous@predli.com\\nShivay Nagpal\\nPredli\\nshivay@predli.com\\nAlexander Fred-Ojala\\nPredli & UC Berkeley\\nafo@berkeley.edu\\nApril 2, 2024\\nAbstract\\nRetrieval-Augmented Generation (RAG) is essential for integrating external knowledge into\\nLarge Language Model (LLM) outputs. While the literature on RAG is growing, it primarily\\nfocuses on systematic reviews and comparisons of new state-of-the-art (SoTA) techniques against\\ntheir predecessors, with a gap in extensive experimental comparisons. This study begins to address\\nthis gap by assessing various RAG methods’ impacts on retrieval precision and answer similarity.\\nWe found that Hypothetical Document Embedding (HyDE) and LLM reranking significantly en-\\nhance retrieval precision. However, Maximal Marginal Relevance (MMR) and Cohere rerank did\\nnot exhibit notable advantages over a baseline Naive RAG system, and Multi-query approaches\\nunderperformed. Sentence Window Retrieval emerged as the most effective for retrieval precision,\\ndespite its variable performance on answer similarity. The study confirms the potential of the\\nDocument Summary Index as a competent retrieval approach. All resources related to this re-\\nsearch are publicly accessible for further investigation through our GitHub repository ARAGOG.\\nWe welcome the community to further this exploratory study in RAG systems.\\n1 Introduction\\nLarge Language Models (LLMs) have significantly advanced the field of natural language processing,\\nenabling a wide range of applications from text generation to question answering. However, inte-\\ngrating dynamic, external information remains a challenge for these models. Retrieval Augmented\\nGeneration (RAG) techniques address this limitation by incorporating external knowledge sources into\\nthe generation process, thus enhancing the models’ ability to produce contextually relevant and in-\\nformed outputs. This integration of retrieval mechanisms with generative models is a key development\\nin improving the performance and versatility of LLMs, facilitating more accurate and context-aware\\nresponses. See Figure 1 for an overview of the standard RAG workflow.\\nDespite the growing interest in RAG techniques within the domain of LLMs, the existing body of\\nliterature primarily consists of systematic reviews (Gao et al., 2024) and direct comparisons between\\nsuccessive state-of-the-art (SoTA) models (Gao et al., 2022; Jiang et al., 2023). This pattern reveals\\na notable gap: a comprehensive experimental comparison across a broad spectrum of advanced RAG\\ntechniques is missing. Such a comparison is crucial for understanding the relative strengths and\\nweaknesses of these techniques in enhancing LLMs’ performance across various tasks. This study seeks\\nto contribute to bridging this gap by providing an extensive evaluation of multiple RAG techniques\\nand their combinations, thereby offering insights into their efficacy and applicability in real-world\\nscenarios.\\nThe focus of this investigation is a spectrum of advanced RAG techniques aimed at optimizing the\\nretrieval process. These techniques can be categorized into several areas:\\n1\\narXiv:2404.01037v1  [cs.CL]  1 Apr 2024'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 1, 'page_label': '2'}, page_content='RAG Technique Type\\nSentence-window retrieval Decoupling of Retrieval and GenerationDocument summary index\\nHyDE Query ExpansionMulti-query\\nMaximal Marginal Relevance (MMR) Enhancement Mechanism\\nCohere Re-ranker Re-rankersLLM-based Re-ranker\\nTo evaluate the RAG techniques, this study leverages two metrics: Retrieval Precision and Answer\\nSimilarity (Tonic AI, 2023). Retrieval Precision measures the relevance of the retrieved context to the\\nquestion asked, while Answer Similarity assesses how closely the system’s answers align with reference\\nresponses, on a scale from 0 to 5.\\nFigure 1: A high-level overview of the workflow within a Retrieval-Augmented Generation (RAG) system. This\\nprocess diagram shows how a user query is processed by the system to retrieve relevant documents from a database\\nand how these documents inform the generation of a response.\\n2 RAG Techniques\\n2.1 Sentence-window retrieval\\nThe Sentence-window Retrieval technique is grounded in the principle of optimizing both retrieval\\nand generation processes by tailoring the text chunk size to the specific needs of each stage (Yang,\\n2023). For retrieval, this technique emphasizes single sentences to take advantage of small data\\nchunks for potentially better retrieving capabilities. On the generation side, it adds more sentences\\naround the initial one to offer the LLM extended context, aiming for richer, more detailed outputs.\\nThis decoupling is supposed to increase the performance of both retrieval and generation, ultimately\\nleading to better performance of the whole RAG system.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 2, 'page_label': '3'}, page_content='2.2 Document summary index\\nThe Document Summary Index method enhances RAG systems by indexing document summaries for\\nefficient retrieval, while providing LLMs with full text documents for response generation (Liu, 2023a).\\nThis decoupling strategy optimizes retrieval speed and accuracy through summary-based indexing and\\nsupports comprehensive response synthesis by utilizing the original text.\\n2.3 HyDE\\nThe Hypothetical Document Embedding (Gao et al., 2022) technique enhances the document retrieval\\nby leveraging LLMs to generate a hypothetical answer to a query. HyDE capitalizes on the ability of\\nLLMs to produce context-rich answers, which, once embedded, serve as a powerful tool to refine and\\nfocus document retrieval efforts. See Figure 2 for overview of HyDE RAG system workflow.\\nFigure 2: The process flow of Hypothetical Document Embedding (HyDE) technique within a Retrieval-\\nAugmented Generation system. The diagram illustrates the steps from the initial query input to the generation\\nof a hypothetical answer and its use in retrieving relevant documents to inform the final generated response.\\n2.4 Multi-query\\nThe Multi-query technique (Langchain, 2023) enhances document retrieval by expanding a single user\\nquery into multiple similar queries with the assistance of an LLM. This process involves generating N\\nalternative questions that echo the intent of the original query but from different angles, thereby cap-\\nturing a broader spectrum of potential answers. Each query, including the original, is then vectorized\\nand subjected to its own retrieval process, which increases the chances of fetching a higher volume\\nof relevant information from the document repository. To manage the resultant expanded dataset,\\na re-ranker is often employed, utilizing machine learning models to sift through the retrieved chunks\\nand prioritize those most relevant in regards to the initial query. See Figure 3 for an overview of how\\nMulti-query RAG system workflow.\\n2.5 Maximum Marginal Relevance\\nThe Maximal Marginal Relevance (MMR) technique (Carbonell and Goldstein, 1998) aims to refine\\nthe retrieval process by striking a balance between relevance and diversity in the documents retrieved.\\nBy employing MMR, the retrieval system evaluates potential documents not only for their closeness\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 3, 'page_label': '4'}, page_content='Figure 3: This diagram showcases how multiple similar queries are generated from an initial user query, and how\\nthey contribute to retrieving a wider range of relevant documents.\\nto the query’s intent but also for their uniqueness compared to documents already selected. This\\napproach mitigates the issue of redundancy, ensuring that the set of retrieved documents covers a\\nbroader range of information.\\n2.6 Cohere Rerank\\nRerankers aim to enhance the RAG process by refining the selection of documents retrieved in response\\nto a query, with the goal of prioritizing the most relevant and contextually appropriate information\\nfor generating responses (Pinecone, 2023). This step employs ML algorithms (such as cross-encoder)\\nto reassess the initially retrieved set, using criteria that extend beyond cosine similarity. Through\\nthis evaluation, rerankers are expected to improve the input for generative models, potentially leading\\nto more accurate and contextually rich outputs. See Figure 4 for an overview of the Reranker RAG\\nsystem workflow.\\nOne tool in this domain is Cohere rerank, which uses a cross-encoder architecture to assess the\\nrelevance of documents to the query. This approach differs from methods that process queries and doc-\\numents separately, as cross-encoders analyze them jointly, which could allow for a more comprehensive\\nunderstanding of their mutual relevance.\\n2.7 LLM rerank\\nFollowing the introduction of cross-encoder based rerankers such as Cohere rerank, the LLM reranker\\noffers an alternative strategy by directly applying LLMs to the task of reranking retrieved documents\\n(Liu, 2023b). This method prioritizes the comprehensive analytical abilities of LLMs over the joint\\nquery-document analysis typical of cross-encoders. Although less efficient in terms of processing speed\\nand cost compared to cross-encoder models, LLM rerankers can achieve higher accuracy by leveraging\\nthe advanced understanding of language and context inherent in LLMs. This makes the LLM reranker\\nsuitable for applications where the quality of the reranked results is more critical than computational\\nefficiency. Figure 4 workflow applies to LLM reranker as well.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 4, 'page_label': '5'}, page_content='Figure 4: This flowchart outlines the reranking process in a RAG system. It illustrates how retrieved documents\\nare further assessed for relevance using a reranking step, which refines the set of documents that will inform the\\ngenerated response.\\n3 Methods\\n3.1 Data\\nThis study utilizes a tailored dataset derived from the AI ArXiv collection, accessible via Hugging\\nFace (James Calam, 2023). The dataset consists of 423 selected research papers centered around the\\nthemes of AI and LLMs, sourced from arXiv. This selection offers a comprehensive foundation for\\nconstructing a database to test the RAG techniques and creating a set of evaluation data to assess\\ntheir effectiveness.\\n3.1.1 RAG Database Construction\\nFor the study, a subset of 13 key research papers was selected for their potential to generate specific,\\ntechnical questions suitable for evaluating Retrieval-Augmented Generation (RAG) systems. Among\\nthe selected papers were significant contributions such as RoBERTa: A Robustly Optimized BERT\\nPretraining Approach(Liu et al., 2019) and BERT: Pre-training of Deep Bidirectional Transformers\\nfor Language Understanding (Devlin et al., 2019). To better simulate a real-world vector database\\nenvironment, where noise and irrelevant documents are present, the database was expanded to include\\nthe full dataset of 423 papers available. The additional 410 papers act as noise, enhancing the\\ncomplexity and diversity of the retrieval challenges faced by the RAG system.\\n3.1.2 Chunking Approach\\nMultiple chunking strategies were utilized to create vector databases for different retrieval methods.\\nFor the classic vector database, a TokenTextSplitter was employed with a chunk size of 512 tokens\\nand an overlap of 50 tokens. This approach split the documents into smaller chunks while maintain-\\ning context by allowing for overlapping text between chunks. For the sentence window method, a\\nSentenceWindowNodeParser was used with a window size of 3 sentences, effectively creating overlap-\\nping chunks consisting of three consecutive sentences. Lastly, for the document summary index, a\\nTokenTextSplitter was employed with a larger chunk size of 3072 tokens and an overlap of 100 tokens,\\ngenerating larger chunks to be summarized by the language model.\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 5, 'page_label': '6'}, page_content='3.1.3 Evaluation Data Preparation\\nThe evaluation dataset comprises 107 question-answer (QA) pairs generated with the assistance of\\nGPT-4. The generation process was guided by specific criteria to ensure that the questions were\\nchallenging, technically precise, and reflective of potential user inquiries sent to a RAG system. Each\\nQA pair was then reviewed by humans to validate its relevance and accuracy, ensuring that the\\nevaluation data accurately measures the RAG techniques’ performance in real-world applications.\\nThe QA dataset is available in this paper’s associated Github repository ARAGOG. See Figure 5 for\\nan overview of the data preparation process.\\nFigure 5: The visualization of the AI ArXiv dataset preparation process. This diagram shows the selection of\\npapers for question-answer generation, the employment of the full dataset to provide ample noise for the RAG\\nsystem, and the chunking approaches used to process the documents for the vector database.\\n3.2 Mitigating LLM Output Variability\\nTo address the inherent variability of LLM outputs, the methodology included conducting 10 runs for\\neach RAG technique. This strategy was chosen to balance the need for statistical reliability against the\\nlimitations of computational resources and time. While more runs could increase statistical reliability,\\nthey would also complicate the need to distinguish between statistical and practical significance.\\n3.3 Metrics\\nTo evaluate the performance of various RAG techniques within this study, two primary metrics were\\nemployed from the Tonic Validate package/platform: Retrieval Precision and Answer Similarity (Tonic\\nAI, 2023). These metrics were selected to evaluate both the retrieval process and the generative\\ncapabilities of the LLMs used, with a primary focus on the precision of information retrieval.\\n3.3.1 Retrieval Precision\\nThis metric serves as the cornerstone of the evaluation, directly measuring the efficacy of the retrieval\\ntechniques implemented in the RAG system. Retrieval Precision quantifies the percentage of context\\nretrieved by the system that is relevant to answering a given question, with scores ranging from 0 to\\n1. A higher score indicates a greater proportion of the retrieved content is pertinent to the query.\\nThe evaluation is conducted by asking an LLM evaluator to determine the relevance of each piece\\nof retrieved context, ensuring that the assessment focuses on the accuracy of information retrieval,\\nrather than the subsequent generation quality. See Figure 6 for visual explanation of retrieval precision\\ngrading workflow.\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 6, 'page_label': '7'}, page_content='Figure 6: This diagram illustrates the evaluation process in a RAG system, where each chunk’s relevance is scored,\\ncontributing to the overall retrieval precision metric. The process highlights how individual chunks are evaluated\\nfor their utility in responding to user queries.\\n3.3.2 Answer Similarity\\nAs a complementary metric, Answer Similarity assesses how well the answers generated by the RAG\\nsystem align with reference answers, scored on a scale from 0 to 5. While this end-to-end test provides\\nvaluable insights into the system’s overall performance, it was considered secondary to the primary\\nobjective of evaluating retrieval techniques. This is because Answer Similarity could be influenced by\\nthe generative capabilities of the LLM, potentially confounding the assessment of retrieval effectiveness\\nalone.\\n3.3.3 Rationale for Metric Selection\\nTo select appropriate metrics for the study the goal was to move beyond simplistic measures of\\nsimilarity, such as cosine similarity between embeddings (which do not fully capture the complexity\\nof effective retrieval and generation). The landscape of available metrics and evaluation platforms\\nrevealed a lack of consensus on optimal evaluation strategies for RAG systems, particularly with a focus\\non retrieval. While some methods, such as those proposed by RAGAS (RAGAS Documentation, 2023),\\ninvolve detailed calculations with LLMs and F1 scores, these were deemed to be unsuitable for the\\nobjectives in this paper. Their complexity often led to results that were unreliable. Conversely, simple\\nembedding comparisons were deemed insufficient for capturing the nuanced effectiveness of retrieval\\ntechniques. Ultimately, the selection of Retrieval Precision as the primary metric, complemented by\\nAnswer Similarity, was driven by the focus on evaluating the retrieval component of RAG systems.\\nThough confident in the appropriateness of these metrics, especially Retrieval Precision, one has to\\nacknowledge the ongoing development in this area and remain open to future advancements and\\nconsensus in evaluation methodologies.\\n3.4 LLM\\nFor the experimental setup GPT-3.5-turbo was selected because of its cost-effectiveness and ease of\\nimplementation. Tonic Validate’s requirement for OpenAI models led us to choose GPT-3.5-turbo\\ndue to its cost-effectiveness, even though GPT-4 might provide more precise grading at a higher\\nexpense. It is important to note that the choice of the LLM used for generation itself was less critical\\nfor the main objective—evaluating retrieval precision, since answer similarity can be regarded as a\\nsupplementary metric.\\n4 Results\\nThe study systematically evaluates a variety of advanced RAG techniques using metrics of Retrieval\\nPrecision and Answer Similarity. A comparative analysis is presented through boxplots to visualize the\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 7, 'page_label': '8'}, page_content='distribution of these metrics, followed by ANOVA and Tukey’s HSD tests to determine the statistical\\nsignificance of the differences observed.\\n4.1 Comparative Performance Analysis: Boxplots\\nThe boxplots for Retrieval Precision (Figure 7) indicate varied performance across RAG techniques.\\nThe Sentence Window Retrieval approach is notably effective, with a high median precision, though\\nthis does not directly correlate with Answer Similarity performance (see Figure 8). Techniques utiliz-\\ning LLM Rerank and Hypothetical Document Embedding (HyDE) show enhanced precision, markedly\\noutperforming the Naive RAG baseline. Conversely, Maximal Marginal Relevance (MMR) and Co-\\nhere Rerank demonstrate limited benefits, with median precision scores comparable to or below the\\nbaseline. Multi-query, interestingly, presents a reduction in retrieval precision compared to Naive\\nRAG, warranting further investigation into its application. Document summary index performance\\nis similar to the best setting of Classic VDB, indicating that with further enhancements, Document\\nsummary technique would surpass Classic VDB.\\nFigure 7: Boxplot of Retrieval Precision by Experiment. Each boxplot demonstrates the range and dis-\\ntribution of retrieval precision scores across different RAG techniques. Higher median values and tighter\\ninterquartile ranges suggest better performance and consistency.\\nThe analysis of answer similarity (Figure 8) presents intriguing patterns that both align with and\\ndiverge from those observed in retrieval precision. For Classic Vector Database (VDB) techniques\\nand Document Summary Index, there is a notable positive correlation between retrieval precision and\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 8, 'page_label': '9'}, page_content='answer similarity, suggesting that when relevant information is accurately retrieved, it can lead to\\nanswers that more closely mirror reference responses.\\nIn contrast, Sentence Window Retrieval displays a disparity between high retrieval precision and\\nlower answer similarity scores. This could indicate that while the technique is adept at identifying\\nrelevant passages, it may not be translating this information into answers that are semantically parallel\\nto the reference, possibly due to the generation phase not fully leveraging the retrieved context.\\nFigure 8: Boxplot of Answer Similarity by Experiment. Each boxplot demonstrates the range and dis-\\ntribution of answer similarity scores across different RAG techniques. Higher median values and tighter\\ninterquartile ranges suggest better performance and consistency.\\n4.2 Statistical Validation of Differences\\nAs described in section 3.2, 10 iterations of each experiment were conducted to mitigate the im-\\npact of inherent LLM variability on the results. An ANOVA test applied to these results confirmed\\nsignificant differences in Retrieval Precision across the various techniques, validating that observed\\nvariations were not due to random chance but reflect true performance disparities. Following this,\\nTukey’s Honestly Significant Difference (HSD) test provided a more granular understanding of these\\nperformance differentials. The statistical tests focus only on the primary metric of this study, retrieval\\nprecision. In light of the extensive range of possible pairwise comparisons, the analysis concentrated\\non the comparisons deemed to be most relevant.\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 9, 'page_label': '10'}, page_content='4.2.1 Classic VDB\\nThe Tukey post-hoc test results for the Classic VDB setup confirm that both HyDE and its combina-\\ntions with Cohere Rerank and LLM Rerank significantly outperform the Naive RAG, aligning with the\\nboxplot observations of higher retrieval precision. Significant improvemnt is also observed for LLM\\nRerank alone. However, the Maximal Marginal Relevance (MMR) and Cohere Rerank do not show a\\nsignificant improvement over Naive RAG, which is also reflected in their closer median precision scores\\nin the boxplots. Interestingly, the Multi Query + Reciprocal technique, while statistically significant,\\npresents a mean difference suggesting lower performance compared to Naive RAG, contradicting the\\nanticipated outcome and calling for additional scrutiny.\\nTechnique Comparison Mean Diff. P-adj Reject Null\\nCohere Rerank Naive RAG -0.0150 0.4515 False\\nHyDE Naive RAG -0.0648 0.0000 True\\nHyDE + Cohere Rerank Naive RAG -0.0371 0.0000 True\\nHyDE + LLM Rerank Naive RAG -0.0749 0.0000 True\\nLLM Rerank Naive RAG -0.0514 0.0000 True\\nMaximal Marginal Relevance (MMR) Naive RAG -0.0156 0.3787 False\\nMulti Query + Cohere Rerank Naive RAG 0.0012 1.0000 False\\nMulti Query + Reciprocal Naive RAG 0.0542 0.0000 True\\nTable 1: Tukey’s HSD test results comparing RAG techniques to Naive RAG, all within the\\nClassic VDB framework\\nNext, the focus is on techniques which have shown statistically significant improvement over the\\nNaive RAG approach. The table below presents the results from Tukey’s post-hoc tests, contrasting\\neach of the high-performing techniques against each other.\\nTechnique Comparison Mean Diff. P-adj Reject Null\\nHyDE HyDE + Cohere Rerank -0.0277 0.0002 True\\nHyDE HyDE + LLM Rerank 0.0101 0.3255 False\\nHyDE LLM Rerank -0.0134 0.1175 False\\nHyDE + Cohere Rerank HyDE + LLM Rerank 0.0378 0.0000 True\\nHyDE + Cohere Rerank LLM Rerank 0.0143 0.0842 False\\nHyDE + LLM Rerank LLM Rerank -0.0235 0.0015 True\\nTable 2: Tukey’s HSD test results of RAG techniques that offer significant improvement over\\nNaive RAG\\nThe combination of HyDE and LLM Rerank emerged as the most potent in enhancing retrieval\\nprecision within the Classic VDB framework, surpassing other techniques. However, this superior\\nperformance comes with higher latency and cost implications due to the additional LLM calls required\\nfor both reranking and hypothetical document embedding. Close second is HyDE alone, not showing\\nsignificant difference from HyDE + LLM rerank combination. Experiments including Cohere Rerank\\ndid not demonstrate anticipated benefits.\\n4.2.2 Sentence window\\nThis section delves into the analysis of Sentence Window retrieval techniques. First, the worst sentence\\nwindow retriever technique is compared with the best classic VDB technique.\\nThe Tukey’s HSD test clearly indicates that even the least performing Sentence Window technique\\nsurpasses the best Classic VDB method in retrieval precision. This underscores the potential of the\\nSentence Window approach in RAG systems. However, the contrasting results from the Answer Sim-\\nilarity metric serve as a reminder to interpret these findings cautiously.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 10, 'page_label': '11'}, page_content='Technique Comparison Mean Diff. P-adj Reject Null\\nHyDE + LLM Rerank Sentence Window + Cohere Rerank 0.1021 0.0000 True\\nTable 3: Tukey’s HSD test results for the best performing Classic VDB technique against the\\nworst Sentence Window retrieval technique.\\nNext is a comparison of individual Sentence Window retrieval variants.\\nBase Technique Compared Technique Mean Diff. P-adj Reject Null\\nSentence Window Sentence Window + Cohere Rerank 0.0090 0.9768 False\\nSentence Window Sentence Window + HyDE -0.0025 1.0000 False\\nSentence Window Sentence Window + HyDE + Cohere Rerank -0.0078 0.9945 False\\nSentence Window Sentence Window + LLM Rerank 0.0332 0.0000 True\\nTable 4: Tukey’s HSD test results for Sentence Window retrieval enhancements\\nThe Tukey’s HSD test delineates Sentence Window retrieval with LLM Rerank as the only variant\\nto offer a statistically significant improvement over the base Sentence Window technique.\\n4.2.3 Document Summary Index\\nThe Document Summary Index technique was analyzed, focusing on two variations: one augmented\\nwith Cohere Rerank and another with HyDE plus Cohere Rerank. The choice to limit the study to\\nthese two is due to computational constraints and the need for comparability across experiments. The\\ntable below shows that there is no significant difference between the two techniques.\\nTechnique Comparison Mean Diff. P-adj Reject Null\\nDoc Sum + Cohere Re Doc Summ + HyDE + Cohere Re 0.0109 0.8935 False\\nTable 5: Tukey’s HSD test results comparing Document Summary Index variants\\nTo finish off the analysis, a basic version of every vector database set up were compared with\\nanother, i.e. Sentence Window, Naive RAG and Document Summary with Cohere rerank. Utilizing\\nplain Document Summary without enhancements was not feasible for this analysis, as it aggregates\\nmultiple chunks into one summary, leading to results not directly comparable to other techniques that\\noperate on different chunk quantities.\\nTechnique Comparison Mean Diff. P-adj Reject Null\\nDoc Summ Index + Cohere Rerank Classic VDB + Naive RAG 0.0545 0.0000 True\\nDoc Summ Index + Cohere Rerank Sentence Window Retrieval 0.1679 0.0000 True\\nClassic VDB + Naive RAG Sentence Window Retrieval 0.1134 0.0000 True\\nTable 6: Tukey’s HSD test results comparing the performance of Sentence Window retrieval and Document Summary\\nIndex + Cohere Rerank against the baseline Naive RAG\\nThe Tukey’s HSD test results establish the Sentence Window retrieval as the leading technique, sur-\\npassing the Document Summary Index in precision. Document Summary Index with Cohere Rerank\\ntrails behind as a viable second, whereas the Classic VDB, in its standard form, demonstrates the\\nleast retrieval precision among the evaluated techniques.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 11, 'page_label': '12'}, page_content='5 Limitations\\n• Model selection: We used GPT-3.5-turbo for evaluating responses due to the constraints of\\nTonic Validate, which requires the use of OpenAI models. The choice of GPT-3.5-turbo, while\\ncost-effective, may not offer the same depth of analysis as more advanced models like GPT-4.\\n• Data and question scope:The study was conducted using a singular dataset and a set of 107\\nquestions, which may affect the generalizability of the findings across different LLM applications.\\nExpanding the variety of datasets and questions could potentially yield more comprehensive\\ninsights.\\n• Chunking variability: While the use of multiple chunking strategies allowed for a compre-\\nhensive evaluation of different retrieval methods, it also highlighted the inherent challenges in\\ndirectly comparing their performance against the same metrics. Each retrieval method required\\na distinct chunking approach tailored to its specific needs. For instance, the sentence window\\nretrieval method necessitated overlapping chunks of consecutive sentences, while the document\\nsummary index used larger chunks to leverage the language model’s summarization capabilities\\neffectively. Consequently, the retrieval methods were evaluated on chunk types with varying de-\\ngrees of context and information density, making it difficult to draw definitive conclusions about\\ntheir relative strengths and weaknesses. This limitation stems from the fundamental differences\\nin how these retrieval methods operate and the distinct chunking requirements they impose.\\n• Evaluation metrics:The lack of a clear consensus on the optimal metrics for evaluating RAG\\nsystems means our chosen metrics—Retrieval Precision and Answer Similarity—are based on\\nconceptual alignment rather than empirical evidence of their efficacy. This highlights an area\\nfor future research to solidify the evaluation framework for RAG systems.\\n• Technique Selection:The subset of RAG techniques evaluated, while selected based on cur-\\nrent relevance and potential, is not exhaustive. Excluded techniques such as Step back prompt-\\ning (Dai et al., 2023), Auto-merging retrieval (Phaneendra, 2023), and Hybrid search (Akash,\\n2023) reflect the study’s scope limitation and the subjective nature of selection. Future research\\nshould consider these and other emerging methods to broaden the understanding of RAG system\\nenhancements.\\n6 Conclusion\\nOur investigation into Retrieval-Augmented Generation (RAG) techniques has identified HyDE and\\nLLM reranking as notable enhancers of retrieval precision in LLMs. These approaches, however,\\nnecessitate additional LLM queries, incurring greater latency and cost. Surprisingly, established\\ntechniques like MMR and Cohere rerank did not demonstrate significant benefits, and Multi-query\\nwas found to be less effective than baseline Naive RAG.\\nThe results demonstrate the efficacy of the Sentence Window Retrieval technique in achieving high\\nprecision for retrieval tasks, although a discrepancy was observed between retrieval precision and an-\\nswer similarity scores. Given its conceptual similarity to Sentence Window retrieval, we suggest that\\nAuto-merging retrieval (Phaneendra, 2023) might offer comparable benefits, warranting future inves-\\ntigation. The Document Summary Index approach also exhibited satisfactory performance, however,\\nit requires an upfront investment in generating summaries for each document in the corpus.\\nDue to constraints such as dataset singularity, limited questions, and the use of GPT-3.5-turbo for\\nevaluation, the results may not fully capture the potential of more advanced models. Future studies\\nwith broader datasets and higher-capability LLMs could provide more comprehensive insights. This\\nresearch contributes a foundational perspective to the field, encouraging subsequent works to refine,\\nvalidate, and expand upon our findings.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 12, 'page_label': '13'}, page_content='To facilitate this continuation of research and allow for the replication and extension of our work,\\nwe have made our experimental pipeline available through a publicly accessible GitHub repository.\\n(Predlico, 2024)\\n7 Future Work\\n• Knowledge Graph RAG:Integrating Knowledge Graphs (KGs) with RAG systems represents\\na promising direction for enhancing retrieval precision and contextual relevance. KGs offer a\\nwell-organized framework of relationship-rich data that could refine the retrieval phase of RAG\\nsystems (Bratanic, 2023). Although setting up such systems is resource-demanding, the potential\\nfor significantly improved retrieval processes justifies further investigation.\\n• Unfrozen RAG systems:Unlike the static application of RAG systems in our study, future\\ninvestigations can benefit from adapting RAG components, including embedding models and\\nrerankers, directly to specific datasets (Gao et al., 2024; Kiela, 2024). This ”unfrozen” approach\\nallows for fine-tuning on nuanced use-case data, potentially enhancing system specificity and\\noutput quality. Exploring these adaptations could lead to more adaptable and effective RAG\\nsystems tailored to diverse application needs.\\n• Experiment replication across diverse datasets:To ensure the robustness and general-\\nizability of our findings, it is imperative for future research to replicate our experiments using\\na variety of datasets. Conducting these experiments across multiple datasets is important to\\nverify the applicability of our results and to identify any context-specific adjustments needed.\\n• Auto-RAG: The idea of automatically optimizing RAG systems, akin to Auto-ML’s approach\\nin traditional machine learning, presents a significant opportunity for future exploration. Cur-\\nrently, selecting the optimal configuration of RAG components — e.g., chunking strategies,\\nwindow sizes, and parameters within rerankers — relies on manual experimentation and intu-\\nition. An automated system could systematically explore a vast space of RAG configurations\\nand select the very best model (Markr.AI, 2024).\\nReferences\\nAkash. Hybrid search: Optimizing rag implementation. https://medium.com/@csakash03/\\nhybrid-search-is-a-method-to-optimize-rag-implementation-98d9d0911341 , 2023. Ac-\\ncessed: 2024-04-01.\\nT. Bratanic. Using a knowledge graph to implement a rag application. https://neo4j.com/\\ndeveloper-blog/knowledge-graph-rag-application/ , 2023. Accessed: 2024-03-24.\\nJ. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and\\nproducing summaries. https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_\\nBased_LTMIR_1998.pdf, 1998. Accessed: 2024-03-24.\\nZ. Dai, J. Callan, K.-W. Chang, D. Chen, K. Guu, X. Han, K. Hashimoto, H. He, M. Joshi,\\nD. Jurafsky, J. Karishnamurthy, D. Khashabi, D. Kiela, A. Kumar, Z. Lan, M. Lewis, X. Ma,\\nS. Min, A. Neelakantan, A. Y. Ng, P. Pasupat, P. Qi, C. Raffel, S. Roller, K. Shih, and\\nL. Zettlemoyer. Step back prompting: Enhancing llms with historical context retrieval. https:\\n//arxiv.org/abs/2310.06117, 2023.\\nJ. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional trans-\\nformers for language understanding, 2019.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-02T04:16:02+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'total_pages': 14, 'page': 13, 'page_label': '14'}, page_content='L. Gao, X. Ma, J. Lin, and J. Callan. Precise zero-shot dense retrieval without relevance labels, 2022.\\nY. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, Q. Guo, M. Wang, and H. Wang.\\nRetrieval-augmented generation for large language models: A survey, 2024.\\nJames Calam. Ai arxiv dataset. https://huggingface.co/datasets/jamescalam/ai-arxiv, 2023.\\nAccessed: 2024-03-24.\\nZ. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y. Yang, J. Callan, and G. Neubig. Active\\nretrieval augmented generation, 2023.\\nD. Kiela. Stanford cs25: V3 i retrieval augmented language models. https://www.youtube.com/\\nwatch?v=mE7IDf2SmJg, 2024. Accessed: 2024-03-24.\\nLangchain. Query transformations. https://blog.langchain.dev/query-transformations/, 2023.\\nAccessed: 2024-03-23.\\nJ. Liu. A new document summary index for llm-powered qa systems. https://www.llamaindex.ai/\\nblog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec , 2023a.\\nAccessed: 2024-03-23.\\nJ. Liu. Using llms for retrieval and reranking. https://www.llamaindex.ai/blog/\\nusing-llms-for-retrieval-and-reranking-23cf2d3a14b6 , 2023b. Accessed: 2024-03-24.\\nY. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoy-\\nanov. Roberta: A robustly optimized bert pretraining approach, 2019.\\nMarkr.AI. Autorag: A framework for automated retrieval-augmented generation. https://github.\\ncom/Marker-Inc-Korea/AutoRAG, 2024. Accessed: 2024-03-24.\\nK. Phaneendra. Deep dive into advanced rag applications\\nin llm-based systems. https://phaneendrakn.medium.com/\\ndeep-dive-into-advanced-rag-applications-in-llm-based-systems-1ccee0473b3b , 2023.\\nAccessed: 2024-04-01.\\nPinecone. Rerankers. https://www.pinecone.io/learn/series/rag/rerankers/, 2023. Accessed:\\n2024-03-24.\\nPredlico. Aragog - advanced retrieval augmented generation output grading. https://github.com/\\npredlico/ARAGOG, 2024. Accessed: 2024-03-24.\\nRAGAS Documentation. Metrics. https://docs.ragas.io/en/v0.0.17/concepts/metrics/\\nindex.html, 2023. Accessed: 2024-03-24.\\nTonic AI. About rag metrics: Tonic validate rag metrics summary. https://docs.tonic.ai/\\nvalidate/about-rag-metrics/tonic-validate-rag-metrics-summary , 2023. Accessed: 2024-\\n03-24.\\nS. Yang. Advanced rag 01: Small to big retrieval. https://towardsdatascience.com/\\nadvanced-rag-01-small-to-big-retrieval-172181b396d4 , 2023. Accessed: 2024-03-23.\\n14')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1a9babd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 14\n"
     ]
    }
   ],
   "source": [
    "length = len(texts)\n",
    "print(f\"Number of chunks: {length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0681a",
   "metadata": {},
   "source": [
    "## embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faafde4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kumar\\.conda\\envs\\rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from tqdm import tqdm\n",
    "\n",
    "embeddings_model_name = 'BAAI/bge-large-en'\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00307ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee8bc4",
   "metadata": {},
   "source": [
    "## Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da796c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24cf510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3b7bfff9-3988-42f2-8a0a-9572d26978b9',\n",
       " '269d4808-2cb6-4e8b-a02e-d0b316258ecc',\n",
       " '5248f2f4-fe34-414f-9e3b-ea10fd336a17',\n",
       " '36e5fa0b-c93a-489e-9331-4d3128442472',\n",
       " '659cb641-57d9-40c6-bc28-e50e88016364',\n",
       " '41e43c4f-3d80-471f-8f42-1ee1ff2988d6',\n",
       " '32e55c39-2568-4bb6-9933-6cba4e09e18d',\n",
       " '9cbe48ff-f7b7-44a4-a6f0-f9a2e16fb339',\n",
       " 'e7cc1781-2081-43b4-8c30-b34da4492657',\n",
       " '469557b6-3e63-4cf6-87c7-b89fb4b2065c',\n",
       " '31233fcd-69ea-42d8-bcf5-ff4a8b537e05',\n",
       " 'ab72f14b-13b3-4c81-a516-e1a96581f13b',\n",
       " '8f6a2455-5931-4075-a978-8fa69c4a13a8',\n",
       " 'b3034614-377f-4918-a644-f73adc202ac0']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## adding all documents to the vector store\n",
    "from uuid import uuid4\n",
    "uuids = [str(uuid4()) for _ in range(len(texts))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5ce92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* To facilitate this continuation of research and allow for the replication and extension of our work,\n",
      "we have made our experimental pipeline available through a publicly accessible GitHub repository.\n",
      "(Predlico, 2024)\n",
      "7 Future Work\n",
      "• Knowledge Graph RAG:Integrating Knowledge Graphs (KGs) with RAG systems represents\n",
      "a promising direction for enhancing retrieval precision and contextual relevance. KGs offer a\n",
      "well-organized framework of relationship-rich data that could refine the retrieval phase of RAG\n",
      "systems (Bratanic, 2023). Although setting up such systems is resource-demanding, the potential\n",
      "for significantly improved retrieval processes justifies further investigation.\n",
      "• Unfrozen RAG systems:Unlike the static application of RAG systems in our study, future\n",
      "investigations can benefit from adapting RAG components, including embedding models and\n",
      "rerankers, directly to specific datasets (Gao et al., 2024; Kiela, 2024). This ”unfrozen” approach\n",
      "allows for fine-tuning on nuanced use-case data, potentially enhancing system specificity and\n",
      "output quality. Exploring these adaptations could lead to more adaptable and effective RAG\n",
      "systems tailored to diverse application needs.\n",
      "• Experiment replication across diverse datasets:To ensure the robustness and general-\n",
      "izability of our findings, it is imperative for future research to replicate our experiments using\n",
      "a variety of datasets. Conducting these experiments across multiple datasets is important to\n",
      "verify the applicability of our results and to identify any context-specific adjustments needed.\n",
      "• Auto-RAG: The idea of automatically optimizing RAG systems, akin to Auto-ML’s approach\n",
      "in traditional machine learning, presents a significant opportunity for future exploration. Cur-\n",
      "rently, selecting the optimal configuration of RAG components — e.g., chunking strategies,\n",
      "window sizes, and parameters within rerankers — relies on manual experimentation and intu-\n",
      "ition. An automated system could systematically explore a vast space of RAG configurations\n",
      "and select the very best model (Markr.AI, 2024).\n",
      "References\n",
      "Akash. Hybrid search: Optimizing rag implementation. https://medium.com/@csakash03/\n",
      "hybrid-search-is-a-method-to-optimize-rag-implementation-98d9d0911341 , 2023. Ac-\n",
      "cessed: 2024-04-01.\n",
      "T. Bratanic. Using a knowledge graph to implement a rag application. https://neo4j.com/\n",
      "developer-blog/knowledge-graph-rag-application/ , 2023. Accessed: 2024-03-24.\n",
      "J. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and\n",
      "producing summaries. https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_\n",
      "Based_LTMIR_1998.pdf, 1998. Accessed: 2024-03-24.\n",
      "Z. Dai, J. Callan, K.-W. Chang, D. Chen, K. Guu, X. Han, K. Hashimoto, H. He, M. Joshi,\n",
      "D. Jurafsky, J. Karishnamurthy, D. Khashabi, D. Kiela, A. Kumar, Z. Lan, M. Lewis, X. Ma,\n",
      "S. Min, A. Neelakantan, A. Y. Ng, P. Pasupat, P. Qi, C. Raffel, S. Roller, K. Shih, and\n",
      "L. Zettlemoyer. Step back prompting: Enhancing llms with historical context retrieval. https:\n",
      "//arxiv.org/abs/2310.06117, 2023.\n",
      "J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional trans-\n",
      "formers for language understanding, 2019.\n",
      "13 [{'trapped': '/False', 'producer': 'pdfTeX-1.40.25', 'subject': '', 'title': '', 'creator': 'LaTeX with hyperref', 'keywords': '', 'total_pages': 14, 'creationdate': '2024-04-02T04:16:02+00:00', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'page': 12, 'moddate': '2024-04-02T04:16:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'page_label': '13', 'author': ''}]\n",
      "* To facilitate this continuation of research and allow for the replication and extension of our work,\n",
      "we have made our experimental pipeline available through a publicly accessible GitHub repository.\n",
      "(Predlico, 2024)\n",
      "7 Future Work\n",
      "• Knowledge Graph RAG:Integrating Knowledge Graphs (KGs) with RAG systems represents\n",
      "a promising direction for enhancing retrieval precision and contextual relevance. KGs offer a\n",
      "well-organized framework of relationship-rich data that could refine the retrieval phase of RAG\n",
      "systems (Bratanic, 2023). Although setting up such systems is resource-demanding, the potential\n",
      "for significantly improved retrieval processes justifies further investigation.\n",
      "• Unfrozen RAG systems:Unlike the static application of RAG systems in our study, future\n",
      "investigations can benefit from adapting RAG components, including embedding models and\n",
      "rerankers, directly to specific datasets (Gao et al., 2024; Kiela, 2024). This ”unfrozen” approach\n",
      "allows for fine-tuning on nuanced use-case data, potentially enhancing system specificity and\n",
      "output quality. Exploring these adaptations could lead to more adaptable and effective RAG\n",
      "systems tailored to diverse application needs.\n",
      "• Experiment replication across diverse datasets:To ensure the robustness and general-\n",
      "izability of our findings, it is imperative for future research to replicate our experiments using\n",
      "a variety of datasets. Conducting these experiments across multiple datasets is important to\n",
      "verify the applicability of our results and to identify any context-specific adjustments needed.\n",
      "• Auto-RAG: The idea of automatically optimizing RAG systems, akin to Auto-ML’s approach\n",
      "in traditional machine learning, presents a significant opportunity for future exploration. Cur-\n",
      "rently, selecting the optimal configuration of RAG components — e.g., chunking strategies,\n",
      "window sizes, and parameters within rerankers — relies on manual experimentation and intu-\n",
      "ition. An automated system could systematically explore a vast space of RAG configurations\n",
      "and select the very best model (Markr.AI, 2024).\n",
      "References\n",
      "Akash. Hybrid search: Optimizing rag implementation. https://medium.com/@csakash03/\n",
      "hybrid-search-is-a-method-to-optimize-rag-implementation-98d9d0911341 , 2023. Ac-\n",
      "cessed: 2024-04-01.\n",
      "T. Bratanic. Using a knowledge graph to implement a rag application. https://neo4j.com/\n",
      "developer-blog/knowledge-graph-rag-application/ , 2023. Accessed: 2024-03-24.\n",
      "J. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and\n",
      "producing summaries. https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_\n",
      "Based_LTMIR_1998.pdf, 1998. Accessed: 2024-03-24.\n",
      "Z. Dai, J. Callan, K.-W. Chang, D. Chen, K. Guu, X. Han, K. Hashimoto, H. He, M. Joshi,\n",
      "D. Jurafsky, J. Karishnamurthy, D. Khashabi, D. Kiela, A. Kumar, Z. Lan, M. Lewis, X. Ma,\n",
      "S. Min, A. Neelakantan, A. Y. Ng, P. Pasupat, P. Qi, C. Raffel, S. Roller, K. Shih, and\n",
      "L. Zettlemoyer. Step back prompting: Enhancing llms with historical context retrieval. https:\n",
      "//arxiv.org/abs/2310.06117, 2023.\n",
      "J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional trans-\n",
      "formers for language understanding, 2019.\n",
      "13 [{'creationdate': '2024-04-02T04:16:02+00:00', 'page_label': '13', 'keywords': '', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'author': '', 'creator': 'LaTeX with hyperref', 'title': '', 'trapped': '/False', 'page': 12, 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'producer': 'pdfTeX-1.40.25', 'subject': '', 'moddate': '2024-04-02T04:16:02+00:00', 'total_pages': 14}]\n",
      "* Figure 4: This flowchart outlines the reranking process in a RAG system. It illustrates how retrieved documents\n",
      "are further assessed for relevance using a reranking step, which refines the set of documents that will inform the\n",
      "generated response.\n",
      "3 Methods\n",
      "3.1 Data\n",
      "This study utilizes a tailored dataset derived from the AI ArXiv collection, accessible via Hugging\n",
      "Face (James Calam, 2023). The dataset consists of 423 selected research papers centered around the\n",
      "themes of AI and LLMs, sourced from arXiv. This selection offers a comprehensive foundation for\n",
      "constructing a database to test the RAG techniques and creating a set of evaluation data to assess\n",
      "their effectiveness.\n",
      "3.1.1 RAG Database Construction\n",
      "For the study, a subset of 13 key research papers was selected for their potential to generate specific,\n",
      "technical questions suitable for evaluating Retrieval-Augmented Generation (RAG) systems. Among\n",
      "the selected papers were significant contributions such as RoBERTa: A Robustly Optimized BERT\n",
      "Pretraining Approach(Liu et al., 2019) and BERT: Pre-training of Deep Bidirectional Transformers\n",
      "for Language Understanding (Devlin et al., 2019). To better simulate a real-world vector database\n",
      "environment, where noise and irrelevant documents are present, the database was expanded to include\n",
      "the full dataset of 423 papers available. The additional 410 papers act as noise, enhancing the\n",
      "complexity and diversity of the retrieval challenges faced by the RAG system.\n",
      "3.1.2 Chunking Approach\n",
      "Multiple chunking strategies were utilized to create vector databases for different retrieval methods.\n",
      "For the classic vector database, a TokenTextSplitter was employed with a chunk size of 512 tokens\n",
      "and an overlap of 50 tokens. This approach split the documents into smaller chunks while maintain-\n",
      "ing context by allowing for overlapping text between chunks. For the sentence window method, a\n",
      "SentenceWindowNodeParser was used with a window size of 3 sentences, effectively creating overlap-\n",
      "ping chunks consisting of three consecutive sentences. Lastly, for the document summary index, a\n",
      "TokenTextSplitter was employed with a larger chunk size of 3072 tokens and an overlap of 100 tokens,\n",
      "generating larger chunks to be summarized by the language model.\n",
      "5 [{'creator': 'LaTeX with hyperref', 'total_pages': 14, 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': '', 'keywords': '', 'author': '', 'source': 'C:\\\\Users\\\\kumar\\\\Downloads\\\\rag_paper.pdf', 'producer': 'pdfTeX-1.40.25', 'creationdate': '2024-04-02T04:16:02+00:00', 'moddate': '2024-04-02T04:16:02+00:00', 'subject': '', 'page_label': '5', 'page': 4, 'trapped': '/False'}]\n"
     ]
    }
   ],
   "source": [
    "#creating a retriever\n",
    "results = vector_store.similarity_search(\n",
    "    \"What is rag\",\n",
    "    k=3,\n",
    "    \n",
    ")\n",
    "results\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd142ed4",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6615de",
   "metadata": {},
   "source": [
    "# Method-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b99695",
   "metadata": {},
   "source": [
    "# Connect with alternative LLMs\n",
    "* Talk with Open Source LLMs like Llama3 and Mixtral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cdf9a",
   "metadata": {},
   "source": [
    "## How to get a free Groq API Key\n",
    "* Login into Groq Cloud: [https://console.groq.com/login](https://console.groq.com/login)\n",
    "* Once logged in, click on API Keys (left sidebar).\n",
    "* Create a new API Key.\n",
    "* Copy the API Key and paste it in your .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28e66b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-groq\n",
      "  Downloading langchain_groq-0.3.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-groq) (0.3.66)\n",
      "Collecting groq<1,>=0.28.0 (from langchain-groq)\n",
      "  Downloading groq-0.29.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from groq<1,>=0.28.0->langchain-groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from groq<1,>=0.28.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from groq<1,>=0.28.0->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from groq<1,>=0.28.0->langchain-groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from groq<1,>=0.28.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from groq<1,>=0.28.0->langchain-groq) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.28.0->langchain-groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.28.0->langchain-groq) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.28.0->langchain-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.28.0->langchain-groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-groq) (0.4.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-groq) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.28.0->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.28.0->langchain-groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.28.0->langchain-groq) (0.4.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-groq) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-groq) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-groq) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-groq) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumar\\.conda\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-groq) (2.5.0)\n",
      "Downloading langchain_groq-0.3.4-py3-none-any.whl (15 kB)\n",
      "Downloading groq-0.29.0-py3-none-any.whl (130 kB)\n",
      "Installing collected packages: groq, langchain-groq\n",
      "\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   ---------------------------------------- 0/2 [groq]\n",
      "   -------------------- ------------------- 1/2 [langchain-groq]\n",
      "   ---------------------------------------- 2/2 [langchain-groq]\n",
      "\n",
      "Successfully installed groq-0.29.0 langchain-groq-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d08812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05e0e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llamaChatModel = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf441c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistralChatModel = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cc47e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an historian expert in the Kennedy family.\"),\n",
    "    (\"human\", \"How many members of the family died tragically?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b179d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "llamaResponse = llamaChatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6373d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kennedy family has indeed been plagued by a series of tragic events and untimely deaths. Here's a list of some of the most notable ones:\n",
      "\n",
      "1. Joseph P. Kennedy Jr. (1915-1944): The eldest son of Joseph P. Kennedy Sr. and Rose Fitzgerald Kennedy, Joseph Jr. was a naval aviator who died in a plane crash during a secret mission in World War II.\n",
      "2. Kathleen Kennedy Cavendish (1920-1948): Known as \"Kick,\" Kathleen was a sister of John F. Kennedy and wife of William Cavendish, Marquess of Hartington. She died in a plane crash in France at the age of 28.\n",
      "3. John F. Kennedy (1917-1963): The 35th President of the United States, John F. Kennedy was assassinated in Dallas, Texas, on November 22, 1963.\n",
      "4. Robert F. Kennedy (1925-1968): John's younger brother and Attorney General of the United States, Robert was assassinated on June 5, 1968, while campaigning for the Democratic presidential nomination in Los Angeles.\n",
      "5. David Kennedy (1955-1984): The son of Robert F. Kennedy, David died of a drug overdose in a Florida hotel room at the age of 28.\n",
      "6. Michael Kennedy (1958-1997): Another son of Robert F. Kennedy, Michael died in a skiing accident in Aspen, Colorado, on December 31, 1997, at the age of 39.\n",
      "7. John F. Kennedy Jr. (1960-1999): The son of John F. Kennedy and Jacqueline Kennedy Onassis, John Jr. died in a plane crash off the coast of Massachusetts on July 18, 1999, at the age of 38.\n",
      "8. Kara Kennedy (1960-2011): The daughter of Edward M. Kennedy, Kara died of a heart attack while exercising at a Washington, D.C. gym on September 16, 2011, at the age of 51.\n",
      "9. Mary Richardson Kennedy (1959-2012): The estranged wife of Robert F. Kennedy Jr., Mary died by suicide at her home in Bedford, New York, on May 16, 2012.\n",
      "\n",
      "These tragic events have led some to speak of a \"Kennedy curse,\" although it's worth noting that many of these deaths were the result of accidents, illnesses, or intentional acts rather than any supernatural force.\n"
     ]
    }
   ],
   "source": [
    "print(llamaResponse.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756433b4",
   "metadata": {},
   "source": [
    "# Method-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ba2af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:1b\",\n",
    "    temperature=0,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ed119",
   "metadata": {},
   "source": [
    "# Creating the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b48b26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that answers questions based only on the provided context. \"\n",
    "            \"Be clear, detailed, and explain your reasoning in simple terms. Quote relevant parts of the context if helpful.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Answer the question based only on the following context:\\n\\n{context}\\n\\nQuestion: {question}\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a57973",
   "metadata": {},
   "source": [
    "## Get the Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a222378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, RAG stands for Retrieval-Augmented Generation. It’s a method that enhances retrieval precision and contextual relevance by integrating knowledge graphs with RAG systems.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"what is rag\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf458049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let’s break down how the RAG system works, based solely on the provided text.\n",
      "\n",
      "The text describes the RAG system as a process that involves these key steps:\n",
      "\n",
      "1.  **Data Collection:** It utilizes a tailored dataset derived from the AI ArXiv collection (specifically, 423 research papers centered around AI and LLMs). This dataset is expanded to include the full dataset of 423 papers available.\n",
      "2.  **Chunking:** Multiple chunking strategies are employed to create vector databases for different retrieval methods. This includes:\n",
      "    *   **TokenTextSplitter:** Splits documents into smaller chunks based on 512 tokens and 50 tokens overlap.\n",
      "    *   **SentenceWindowNodeParser:** Splits documents into chunks based on 3 sentences and 100 tokens overlap.\n",
      "    *   **Document Summary Index:** Splits documents into 3072 tokens and 100 tokens overlap.\n",
      "3.  **Reranking:** The system reranks retrieved documents based on relevance using a reranking step.\n",
      "4.  **Refinement:** The reranked documents are then used to inform the generated response.\n",
      "\n",
      "Essentially, the system starts with a large dataset, then breaks it down into smaller chunks, and uses these chunks to create a set of documents that are then evaluated for relevance.  The reranking step refines the set of documents, and the final output is used to generate the response.\n",
      "\n",
      "**In short, the RAG system works by creating a set of documents, then using a reranking process to select the most relevant ones, and then using those selected documents to generate the final response.**\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"how rag works\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7de4ca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, the components of RAG (Retrieval-Augmented Generation) are:\n",
      "\n",
      "*   **Data:** A tailored dataset derived from the AI ArXiv collection, accessible via Hugging Face.\n",
      "*   **Chunking Approach:** Multiple chunking strategies are utilized to create vector databases for different retrieval methods.\n",
      "*   **Reranking Step:** Refines the set of documents that will inform the generated response.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"what are the components of rag\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "730493c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here’s a summary of the paper based on the provided context, aiming for clarity and detail:\n",
      "\n",
      "**The paper describes a RAG (Retrieval-Augmented Generation) system designed to improve the quality of responses generated by language models.**\n",
      "\n",
      "Here’s a breakdown of the key aspects:\n",
      "\n",
      "1.  **Data Source:** The system utilizes a dataset derived from the AI ArXiv collection (accessible via Hugging Face) containing 423 research papers centered around AI and LLMs. This dataset serves as the foundation for testing and evaluating the RAG techniques.\n",
      "\n",
      "2.  **Data Construction – RAG Database:**\n",
      "    *   **Subset of Key Papers:** A subset of 13 research papers was selected for their potential to generate specific technical questions suitable for evaluating RAG systems. These papers included significant contributions from Liu et al. (RoBERTa) and Devlin et al. (BERT).\n",
      "    *   **Expanded Database:** The dataset was expanded to include the full 423 papers available, creating a larger pool of documents for testing.\n",
      "    *   **Noise & Diversity:** The expanded dataset included \"noise\" – irrelevant documents – to enhance the complexity and diversity of the retrieval challenges.\n",
      "\n",
      "3.  **Chunking Strategies:**\n",
      "    *   **TokenTextSplitter:**  Different chunking methods were employed:\n",
      "        *   **Classic Vector Database:**  Documents were split into 512-token chunks with 50-token overlap.\n",
      "        *   **Sentence Window Method:** Documents were split into 3-sentence chunks with overlap.\n",
      "        *   **Document Summary Index:** Documents were split into 3072-token chunks with overlap of 100 tokens.\n",
      "    *   **Purpose of Chunking:**  The chunking strategy was designed to simulate a real-world vector database environment where noise and irrelevant documents are present.\n",
      "\n",
      "4.  **Document Summary Index:**\n",
      "    *   **Enhancement:** The Document Summary Index method was used to improve RAG systems by indexing document summaries. This helps with efficient retrieval.\n",
      "\n",
      "5.  **HyDE (Hypothetical Document Embedding):**\n",
      "    *   **Technique:** HyDE leverages LLMs to generate hypothetical answers to queries, enhancing the context-richness of the responses.\n",
      "\n",
      "6.  **Multi-Query:**\n",
      "    *   **Expanding Queries:** The Multi-Query technique expands a single user query into multiple similar queries, capturing a broader range of potential answers.\n",
      "\n",
      "7.  **Maximum Marginal Relevance:**\n",
      "    *   **Refinement:** The MMR technique is used to refine the retrieval process by prioritizing documents that are highly relevant to the initial query.\n",
      "\n",
      "**In essence, the paper describes a system that uses a carefully constructed dataset and diverse chunking techniques to create a robust RAG system capable of generating high-quality responses to technical questions.**\n",
      "\n",
      "Do you want me to elaborate on any of these points or provide more detail on a specific aspect?\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"summarize the paper\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c033f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
