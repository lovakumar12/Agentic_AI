{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22f1c1d",
   "metadata": {},
   "source": [
    "Step-1 : Extract the PDF text\n",
    "\n",
    "Step-2 : Chunk the extracted PDF text\n",
    "\n",
    "Step-3 : Create a vector store with the PDF chunks\n",
    "\n",
    "Step-4 : Create a retriever which returns the relevant chunks\n",
    "\n",
    "Step-5 : Build context from the relevant chunk texts\n",
    "\n",
    "Step-6 : Build the RAG chain using rag prompt, LLM and string output parser.\n",
    "\n",
    "Step-7 : Run the RAG chain to get the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935e89c",
   "metadata": {},
   "source": [
    "### Install and Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU langchain langchain-community langchain-text-splitters\n",
    "# !pip install -qU langchain-openai langchain-chroma pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356ba4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kumar\\.conda\\envs\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3df0a",
   "metadata": {},
   "source": [
    "## setup llm api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30804f",
   "metadata": {},
   "source": [
    "## Extract pdf Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the PDF file\n",
    "import requests\n",
    "\n",
    "pdf_url = 'https://arxiv.org/pdf/1706.03762'\n",
    "\n",
    "response = requests.get(pdf_url)\n",
    "\n",
    "pdf_path = 'attention_is_all_you_need.pdf'\n",
    "with open(pdf_path, 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146dc632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def pdf_extract(pdf_path: str) -> List[Document]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file using PyPDFLoader.\n",
    "\n",
    "    Parameters:\n",
    "    pdf_path (str): The file path of the PDF to be extracted.\n",
    "\n",
    "    Returns:\n",
    "    List[Document]: A list of Document objects containing the extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    \n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "331304bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text=pdf_extract(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05edc56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pages in pdf: 15\n"
     ]
    }
   ],
   "source": [
    "print(r\"number of pages in pdf:\", len(pdf_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48199765",
   "metadata": {},
   "source": [
    "## Chunk Pdf Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ce7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_chunk(documents: List[Document], chunk_size: int = 1000, chunk_overlap: int = 200) -> List[Document]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Splits the text of documents into smaller chunks using RecursiveCharacterTextSplitter.\n",
    "\n",
    "    Parameters:\n",
    "    documents (List[Document]): A list of Document objects to be split into chunks.\n",
    "    chunk_size (int): The maximum size of each chunk. Default is 1000 characters.\n",
    "    chunk_overlap (int): The number of overlapping characters between chunks. Default is 200 characters.\n",
    "\n",
    "    Returns:\n",
    "    List[Document]: A list of Document objects containing the text chunks.\n",
    "    \"\"\"\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb00557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chunks created: 52\n"
     ]
    }
   ],
   "source": [
    "chunks=pdf_chunk(pdf_text)\n",
    "print(r\"number of chunks created:\", len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c593dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani‚àó\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer‚àó\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar‚àó\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit‚àó\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones‚àó\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez‚àó ‚Ä†\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "≈Åukasz Kaiser‚àó\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin‚àó ‚Ä°\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e3eb1",
   "metadata": {},
   "source": [
    "## Create Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88bc9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB directory created at: c:\\Users\\kumar\\RAG\\vector_db\\chroma_db_pdf\n"
     ]
    }
   ],
   "source": [
    "# Set the chroma DB path\n",
    "import os\n",
    "\n",
    "# Define the directory where you want to store the vector database\n",
    "persist_directory = \"vector_db/chroma_db_pdf\"\n",
    "\n",
    "# Create the directory (including parent folders if needed)\n",
    "os.makedirs(persist_directory, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aa5cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(chunks: List[Document], persist_directory: str) -> Chroma:\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a Chroma vector store from the provided document chunks.\n",
    "\n",
    "    Parameters:\n",
    "    chunks (List[Document]): A list of Document objects to be stored in the vector store.\n",
    "    persist_directory (str): The directory path where the vector store will be persisted.\n",
    "\n",
    "    Returns:\n",
    "    Chroma: An instance of the Chroma vector store containing the document embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en\")\n",
    "    \n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    \n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52637e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = create_vector_store(chunks, persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73917a9b",
   "metadata": {},
   "source": [
    "## Retrive the Relevant Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaeea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrieve_context(db: Chroma, query: str) -> List[Document]:\n",
    "#     \"\"\"\n",
    "#     Retrieves relevant document chunks from the Chroma vector store based on a query.\n",
    "\n",
    "#     Parameters:\n",
    "#     db (Chroma): The Chroma vector store containing embedded documents.\n",
    "#     query (str): The query string to search for relevant document chunks.\n",
    "\n",
    "#     Returns:\n",
    "#     List[Document]: A list of retrieved relevant document chunks.\n",
    "#     \"\"\"\n",
    "\n",
    "#     retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "#     print(\"Relevant chunks are retrieved...\\n\")\n",
    "#     relevant_chunks = retriever.invoke(query)\n",
    "\n",
    "#     return relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da944e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(db, query):\n",
    "    \"\"\"\n",
    "    Retrieves relevant document chunks from the Chroma vector store based on a query.\n",
    "\n",
    "    Parameters:\n",
    "    db (Chroma): The Chroma vector store containing embedded documents.\n",
    "    query (str): The query string to search for relevant document chunks.\n",
    "\n",
    "    Returns:\n",
    "    List[Document]: A list of retrieved relevant document chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "    print(\"Relevant chunks are retrieved...\\n\")\n",
    "    relevant_chunks = retriever.invoke(query)\n",
    "\n",
    "    return relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b703b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant chunks are retrieved...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain transformer model in one line\"\n",
    "\n",
    "relevant_chunks = retrieve_context(db, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b845515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant chunks = 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of relevant chunks = {len(relevant_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79b1c813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk-0\n",
      "page_content='sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "significant improvements in computational efficiency through factorization tricks [21] and conditional\n",
      "computation [32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.' metadata={'keywords': '', 'page': 1, 'page_label': '2', 'creationdate': '2024-04-10T21:11:43+00:00', 'subject': '', 'moddate': '2024-04-10T21:11:43+00:00', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': '', 'source': 'attention_is_all_you_need.pdf', 'total_pages': 15, 'trapped': '/False', 'author': '', 'creator': 'LaTeX with hyperref'}\n",
      "\n",
      "\n",
      "Chunk-1\n",
      "page_content='sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "significant improvements in computational efficiency through factorization tricks [21] and conditional\n",
      "computation [32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.' metadata={'subject': '', 'author': '', 'producer': 'pdfTeX-1.40.25', 'total_pages': 15, 'source': 'attention_is_all_you_need.pdf', 'page_label': '2', 'creationdate': '2024-04-10T21:11:43+00:00', 'page': 1, 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'keywords': '', 'creator': 'LaTeX with hyperref', 'moddate': '2024-04-10T21:11:43+00:00', 'trapped': '/False', 'title': ''}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(relevant_chunks):\n",
    "  print(f\"Chunk-{i}\")\n",
    "  print(chunk)\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d0df80",
   "metadata": {},
   "source": [
    "## Build context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98d6b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(relevant_chunks: List[Document]) -> str:\n",
    "    \"\"\"\n",
    "    Builds a context string from retrieved relevant document chunks.\n",
    "\n",
    "    Parameters:\n",
    "    relevant_chunks (List[Document]): A list of retrieved relevant document chunks.\n",
    "\n",
    "    Returns:\n",
    "    str: A concatenated string containing the content of the relevant chunks.\n",
    "    \"\"\"\n",
    "    print(\"Context is build from the relevant chunks\")  \n",
    "    \n",
    "    context = \"\\n\".join([chunk.page_content for chunk in relevant_chunks])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "501c9bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is build from the relevant chunks\n",
      "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "significant improvements in computational efficiency through factorization tricks [21] and conditional\n",
      "computation [32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "significant improvements in computational efficiency through factorization tricks [21] and conditional\n",
      "computation [32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n"
     ]
    }
   ],
   "source": [
    "context=build_context(relevant_chunks)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f19131",
   "metadata": {},
   "source": [
    "## combine all steps into one Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46c8069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "def get_context(inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Creates or loads a vector store for a given PDF file and extracts relevant chunks based on a query.\n",
    "\n",
    "    Args:\n",
    "        inputs (Dict[str, str]): A dictionary containing the following keys:\n",
    "            - 'pdf_path' (str): Path to the PDF file.\n",
    "            - 'query' (str): The user query.\n",
    "            - 'db_path' (str): Path to the vector database.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing:\n",
    "            - 'context' (str): Extracted relevant context.\n",
    "            - 'query' (str): The user query.\n",
    "    \"\"\"\n",
    "    pdf_path, query, db_path  = inputs['pdf_path'], inputs['query'], inputs['db_path']\n",
    "\n",
    "    # Create new vector store if it does not exist\n",
    "    if not os.path.exists(db_path):\n",
    "        print(\"Creating a new vector store...\\n\")\n",
    "        pdf_text = pdf_extract(pdf_path)\n",
    "        chunks = pdf_chunk(pdf_text)\n",
    "        db = create_vector_store(chunks, db_path)\n",
    "\n",
    "    # Load the existing vector store\n",
    "    else:\n",
    "        print(\"Loading the existing vector store\\n\")\n",
    "        #embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en\")\n",
    "        db = Chroma(persist_directory=db_path, embedding_function=embedding_model)\n",
    "\n",
    "    relevant_chunks = retrieve_context(db, query)\n",
    "    context = build_context(relevant_chunks)\n",
    "\n",
    "    return {'context': context, 'query': query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a4f7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the existing vector store\n",
      "\n",
      "Relevant chunks are retrieved...\n",
      "\n",
      "Context is build from the relevant chunks\n",
      "{'context': 'sequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.', 'query': 'Explain transformer model in one line'}\n"
     ]
    }
   ],
   "source": [
    "context= get_context({'pdf_path': pdf_path, 'query': query, 'db_path': persist_directory})\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe489d",
   "metadata": {},
   "source": [
    "## Build RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "template = \"\"\" You are an AI model trained for question answering. You should answer the\n",
    "  given question based on the given context only.\n",
    "  Question : {query}\n",
    "  \\n\n",
    "  Context : {context}\n",
    "  \\n\n",
    "  If the answer is not present in the given context, respond as: The answer to this question is not available\n",
    "  in the provided content.\n",
    "  \"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "#llm = ChatGroq(model=\"llama3-70b-8192\")\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "rag_chain = (\n",
    "    RunnableLambda(get_context)\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | str_parser\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2248230a",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cb4ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the query\n",
    "query = 'Explain transformer model in one line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0568075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the existing vector store\n",
      "\n",
      "Relevant chunks are retrieved...\n",
      "\n",
      "Context is build from the relevant chunks\n"
     ]
    }
   ],
   "source": [
    "answer = rag_chain.invoke({'pdf_path':pdf_path, 'query':query, 'db_path':persist_directory})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5441ed69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:Explain transformer model in one line\n",
      "\n",
      "Generated answer:The Transformer is a model architecture that relies entirely on an attention mechanism to draw global dependencies between input and output, without using recurrence.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Query:{query}\\n\")\n",
    "print(f\"Generated answer:{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3870b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the existing vector store\n",
      "\n",
      "Relevant chunks are retrieved...\n",
      "\n",
      "Context is build from the relevant chunks\n",
      "\n",
      "Response: Self-attention, sometimes called intra-attention, is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. \n",
      "\n",
      "Loading the existing vector store\n",
      "\n",
      "Relevant chunks are retrieved...\n",
      "\n",
      "Context is build from the relevant chunks\n",
      "\n",
      "Response: The answer to this question is not available in the provided content. \n",
      "\n",
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "\n",
    "    if question.lower() == \"exit\":\n",
    "        print(\"Exiting the program.\")\n",
    "        break\n",
    "\n",
    "    response = rag_chain.invoke({\n",
    "        \"query\": question,\n",
    "        \"pdf_path\": pdf_path,\n",
    "        \"db_path\": persist_directory\n",
    "    })\n",
    "\n",
    "    print(\"\\nResponse:\", response, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1db6d",
   "metadata": {},
   "source": [
    "## streamlit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "388d9a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing rag_app1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rag_app1.py\n",
    "\n",
    "import streamlit as st\n",
    "import requests\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Add error handling for missing API key\n",
    "if not openai_api_key:\n",
    "    st.error(\"‚ùå OPENAI_API_KEY not found in environment variables. Please check your .env file.\")\n",
    "\n",
    "class RAGSystem:\n",
    "    def __init__(self):\n",
    "        self.pdf_path = 'attention_is_all_you_need.pdf'\n",
    "        self.persist_directory = \"vector_db/chroma_db_pdf\"\n",
    "        self.db = None\n",
    "        self.rag_chain = None\n",
    "        self.initialized = False\n",
    "        \n",
    "    def download_pdf(self):\n",
    "        \"\"\"Download the PDF file if not exists\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.pdf_path):\n",
    "                st.info(\"Downloading PDF file...\")\n",
    "                pdf_url = 'https://arxiv.org/pdf/1706.03762'\n",
    "                response = requests.get(pdf_url, timeout=30)\n",
    "                response.raise_for_status()\n",
    "                with open(self.pdf_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                st.success(\"PDF downloaded successfully!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error downloading PDF: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def pdf_extract(self, pdf_path: str) -> List[Document]:\n",
    "        \"\"\"Extract text from PDF\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(pdf_path):\n",
    "                st.error(f\"PDF file not found at {pdf_path}\")\n",
    "                return []\n",
    "                \n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents = loader.load()\n",
    "            st.info(f\"Successfully loaded {len(documents)} pages from PDF\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error loading PDF: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def pdf_chunk(self, documents: List[Document], chunk_size: int = 1000, chunk_overlap: int = 200) -> List[Document]:\n",
    "        \"\"\"Split PDF text into chunks\"\"\"\n",
    "        if not documents:\n",
    "            st.warning(\"No documents to chunk\")\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=chunk_size,\n",
    "                chunk_overlap=chunk_overlap,\n",
    "                length_function=len\n",
    "            )\n",
    "            chunks = text_splitter.split_documents(documents)\n",
    "            st.info(f\"Created {len(chunks)} chunks from documents\")\n",
    "            return chunks\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error chunking documents: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_vector_store(self, chunks: List[Document], persist_directory: str) -> Chroma:\n",
    "        \"\"\"Create Chroma vector store\"\"\"\n",
    "        try:\n",
    "            embedding_model = HuggingFaceEmbeddings(\n",
    "                model_name=\"BAAI/bge-large-en\",\n",
    "                model_kwargs={'device': 'cpu'}\n",
    "            )\n",
    "            \n",
    "            vectordb = Chroma.from_documents(\n",
    "                documents=chunks,\n",
    "                embedding=embedding_model,\n",
    "                persist_directory=persist_directory\n",
    "            )\n",
    "            st.success(\"Vector store created successfully!\")\n",
    "            return vectordb\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error creating vector store: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def retrieve_context(self, db, query: str) -> List[Document]:\n",
    "        \"\"\"Retrieve relevant context from vector store\"\"\"\n",
    "        try:\n",
    "            retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "            relevant_chunks = retriever.invoke(query)\n",
    "            return relevant_chunks\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error retrieving context: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def build_context(self, relevant_chunks: List[Document]) -> str:\n",
    "        \"\"\"Build context string from relevant chunks\"\"\"\n",
    "        if not relevant_chunks:\n",
    "            return \"No relevant context found.\"\n",
    "            \n",
    "        context = \"\\n\".join([chunk.page_content for chunk in relevant_chunks])\n",
    "        return context\n",
    "    \n",
    "    def get_context(self, inputs: dict) -> dict:\n",
    "        \"\"\"Get context for RAG chain\"\"\"\n",
    "        try:\n",
    "            pdf_path, query, db_path = inputs['pdf_path'], inputs['query'], inputs['db_path']\n",
    "            \n",
    "            # Create new vector store if it does not exist\n",
    "            if not os.path.exists(db_path):\n",
    "                st.info(\"Creating a new vector store...\")\n",
    "                pdf_text = self.pdf_extract(pdf_path)\n",
    "                if not pdf_text:\n",
    "                    return {'context': 'No PDF content available.', 'query': query}\n",
    "                chunks = self.pdf_chunk(pdf_text)\n",
    "                if not chunks:\n",
    "                    return {'context': 'No chunks created from PDF.', 'query': query}\n",
    "                db = self.create_vector_store(chunks, db_path)\n",
    "                if not db:\n",
    "                    return {'context': 'Failed to create vector store.', 'query': query}\n",
    "            else:\n",
    "                # Load existing vector store\n",
    "                embedding_model = HuggingFaceEmbeddings(\n",
    "                    model_name=\"BAAI/bge-large-en\",\n",
    "                    model_kwargs={'device': 'cpu'}\n",
    "                )\n",
    "                db = Chroma(persist_directory=db_path, embedding_function=embedding_model)\n",
    "            \n",
    "            relevant_chunks = self.retrieve_context(db, query)\n",
    "            context = self.build_context(relevant_chunks)\n",
    "            \n",
    "            return {'context': context, 'query': query}\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error in get_context: {e}\")\n",
    "            return {'context': f'Error retrieving context: {e}', 'query': inputs['query']}\n",
    "    \n",
    "    def initialize_rag_chain(self):\n",
    "        \"\"\"Initialize the RAG chain\"\"\"\n",
    "        try:\n",
    "            if not openai_api_key:\n",
    "                st.error(\"OpenAI API key not found. Please check your .env file.\")\n",
    "                return False\n",
    "                \n",
    "            template = \"\"\"You are an AI model trained for question answering. You should answer the\n",
    "            given question based on the given context only.\n",
    "            Question: {query}\n",
    "            \n",
    "            Context: {context}\n",
    "            \n",
    "            If the answer is not present in the given context, respond as: The answer to this question is not available\n",
    "            in the provided content.\n",
    "            \"\"\"\n",
    "            \n",
    "            rag_prompt = ChatPromptTemplate.from_template(template)\n",
    "            llm = ChatOpenAI(\n",
    "                model='gpt-4o-mini', \n",
    "                openai_api_key=openai_api_key, \n",
    "                temperature=0,\n",
    "                max_retries=2\n",
    "            )\n",
    "            str_parser = StrOutputParser()\n",
    "            \n",
    "            self.rag_chain = (\n",
    "                RunnableLambda(self.get_context)\n",
    "                | rag_prompt\n",
    "                | llm\n",
    "                | str_parser\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error initializing RAG chain: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def setup(self):\n",
    "        \"\"\"Setup the RAG system\"\"\"\n",
    "        try:\n",
    "            # Download PDF\n",
    "            if not self.download_pdf():\n",
    "                return False\n",
    "            \n",
    "            # Create directory for vector store\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            \n",
    "            # Initialize RAG chain\n",
    "            if self.initialize_rag_chain():\n",
    "                self.initialized = True\n",
    "                st.success(\"RAG System initialized successfully!\")\n",
    "                return True\n",
    "            else:\n",
    "                st.error(\"Failed to initialize RAG chain\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error during setup: {e}\")\n",
    "            return False\n",
    "\n",
    "def save_qa_history(question, answer, context=\"\"):\n",
    "    \"\"\"Save question and answer to session state\"\"\"\n",
    "    if 'qa_history' not in st.session_state:\n",
    "        st.session_state.qa_history = []\n",
    "    \n",
    "    qa_entry = {\n",
    "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'context': context\n",
    "    }\n",
    "    \n",
    "    st.session_state.qa_history.append(qa_entry)\n",
    "\n",
    "def export_qa_history():\n",
    "    \"\"\"Export QA history as JSON file\"\"\"\n",
    "    if 'qa_history' in st.session_state and st.session_state.qa_history:\n",
    "        history_json = json.dumps(st.session_state.qa_history, indent=2)\n",
    "        return history_json\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(\n",
    "        page_title=\"RAG System with Transformers Paper\",\n",
    "        page_icon=\"üìö\",\n",
    "        layout=\"wide\"\n",
    "    )\n",
    "    \n",
    "    st.title(\"ü§ñ RAG System with 'Attention Is All You Need' Paper\")\n",
    "    st.markdown(\"Ask questions about the famous Transformer paper!\")\n",
    "    \n",
    "    # Check for OpenAI API key\n",
    "    if not openai_api_key:\n",
    "        st.error(\"‚ùå OpenAI API key not found. Please make sure you have a .env file with OPENAI_API_KEY=your_key\")\n",
    "        st.info(\"Create a .env file in the same directory with: OPENAI_API_KEY=your_key_here\")\n",
    "        return\n",
    "    \n",
    "    # Initialize RAG system\n",
    "    if 'rag_system' not in st.session_state:\n",
    "        st.session_state.rag_system = RAGSystem()\n",
    "        with st.spinner(\"Initializing RAG system... This may take a few minutes.\"):\n",
    "            success = st.session_state.rag_system.setup()\n",
    "            if not success:\n",
    "                st.error(\"Failed to initialize RAG system. Please check the errors above.\")\n",
    "                return\n",
    "    \n",
    "    # Initialize QA history if not exists\n",
    "    if 'qa_history' not in st.session_state:\n",
    "        st.session_state.qa_history = []\n",
    "    \n",
    "    # Check if system is properly initialized\n",
    "    if not getattr(st.session_state.rag_system, 'initialized', False):\n",
    "        st.error(\"RAG system not properly initialized. Please restart the app.\")\n",
    "        return\n",
    "    \n",
    "    # Display PDF info\n",
    "    with st.expander(\"üìÑ PDF Information\", expanded=False):\n",
    "        if os.path.exists(st.session_state.rag_system.pdf_path):\n",
    "            pdf_text = st.session_state.rag_system.pdf_extract(st.session_state.rag_system.pdf_path)\n",
    "            if pdf_text:\n",
    "                st.write(f\"‚úÖ Number of pages in PDF: {len(pdf_text)}\")\n",
    "                chunks = st.session_state.rag_system.pdf_chunk(pdf_text)\n",
    "                st.write(f\"‚úÖ Number of chunks created: {len(chunks)}\")\n",
    "            else:\n",
    "                st.error(\"‚ùå Failed to load PDF content\")\n",
    "        else:\n",
    "            st.error(\"‚ùå PDF file not found\")\n",
    "    \n",
    "    # Query section\n",
    "    st.subheader(\"üí¨ Ask a Question\")\n",
    "    \n",
    "    # Example questions\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    with col1:\n",
    "        if st.button(\"Explain transformer model\", use_container_width=True):\n",
    "            st.session_state.question = \"Explain transformer model in one line\"\n",
    "    with col2:\n",
    "        if st.button(\"What is attention mechanism?\", use_container_width=True):\n",
    "            st.session_state.question = \"What is attention mechanism?\"\n",
    "    with col3:\n",
    "        if st.button(\"Key contributions\", use_container_width=True):\n",
    "            st.session_state.question = \"What are the key contributions of this paper?\"\n",
    "    \n",
    "    # Question input\n",
    "    question = st.text_input(\n",
    "        \"Enter your question:\",\n",
    "        value=getattr(st.session_state, 'question', ''),\n",
    "        placeholder=\"e.g., Explain transformer model in one line\"\n",
    "    )\n",
    "    \n",
    "    # Process question\n",
    "    if st.button(\"Get Answer\", type=\"primary\") and question:\n",
    "        if not st.session_state.rag_system.rag_chain:\n",
    "            st.error(\"RAG chain not available. Please check if the system initialized correctly.\")\n",
    "            return\n",
    "            \n",
    "        with st.spinner(\"Searching for answer... This may take a few seconds.\"):\n",
    "            try:\n",
    "                answer = st.session_state.rag_system.rag_chain.invoke({\n",
    "                    'pdf_path': st.session_state.rag_system.pdf_path,\n",
    "                    'query': question,\n",
    "                    'db_path': st.session_state.rag_system.persist_directory\n",
    "                })\n",
    "                \n",
    "                st.subheader(\"üìù Answer:\")\n",
    "                st.success(answer)\n",
    "                \n",
    "                # Get context for saving\n",
    "                inputs = {\n",
    "                    'pdf_path': st.session_state.rag_system.pdf_path,\n",
    "                    'query': question,\n",
    "                    'db_path': st.session_state.rag_system.persist_directory\n",
    "                }\n",
    "                context_info = st.session_state.rag_system.get_context(inputs)\n",
    "                context = context_info['context']\n",
    "                \n",
    "                # Save question and answer to history\n",
    "                save_qa_history(question, answer, context)\n",
    "                \n",
    "                # Show retrieved context (optional)\n",
    "                with st.expander(\"üîç View Retrieved Context\"):\n",
    "                    st.text_area(\"Retrieved Context:\", context, height=200, key=\"context_view\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                st.error(f\"Error processing question: {str(e)}\")\n",
    "                st.info(\"This might be due to: 1) PDF not loading properly, 2) Vector store issues, 3) API limits\")\n",
    "    \n",
    "    # Display QA History\n",
    "    if st.session_state.qa_history:\n",
    "        st.subheader(\"üìö Question & Answer History\")\n",
    "        \n",
    "        # Export functionality\n",
    "        history_json = export_qa_history()\n",
    "        if history_json:\n",
    "            st.download_button(\n",
    "                label=\"üì• Export QA History as JSON\",\n",
    "                data=history_json,\n",
    "                file_name=f\"qa_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
    "                mime=\"application/json\",\n",
    "                use_container_width=True\n",
    "            )\n",
    "        \n",
    "        # Display history in reverse order (newest first)\n",
    "        for i, qa in enumerate(reversed(st.session_state.qa_history)):\n",
    "            with st.expander(f\"Q: {qa['question'][:50]}... - {qa['timestamp']}\", key=f\"qa_{i}\"):\n",
    "                st.write(f\"**Question:** {qa['question']}\")\n",
    "                st.write(f\"**Answer:** {qa['answer']}\")\n",
    "                st.write(f\"**Time:** {qa['timestamp']}\")\n",
    "                \n",
    "                # Option to view context for each entry\n",
    "                with st.expander(\"View Context for this question\", key=f\"context_exp_{i}\"):\n",
    "                    st.text_area(f\"Context\", \n",
    "                               qa['context'], \n",
    "                               height=150,\n",
    "                               key=f\"context_text_{i}\")\n",
    "        \n",
    "        # Clear all history\n",
    "        if st.button(\"üóëÔ∏è Clear All History\", key=\"clear_all\", use_container_width=True):\n",
    "            st.session_state.qa_history = []\n",
    "            st.rerun()\n",
    "    else:\n",
    "        st.info(\"No questions asked yet. Ask a question above to see the history here!\")\n",
    "    \n",
    "    # System information\n",
    "    with st.expander(\"‚öôÔ∏è System Information\", expanded=False):\n",
    "        st.write(f\"‚úÖ PDF Path: {st.session_state.rag_system.pdf_path}\")\n",
    "        st.write(f\"‚úÖ Vector DB Path: {st.session_state.rag_system.persist_directory}\")\n",
    "        st.write(f\"‚úÖ Embedding Model: BAAI/bge-large-en\")\n",
    "        st.write(f\"‚úÖ LLM Model: gpt-4o-mini\")\n",
    "        st.write(f\"‚úÖ Total QA pairs saved: {len(st.session_state.qa_history)}\")\n",
    "        st.write(f\"‚úÖ System Initialized: {st.session_state.rag_system.initialized}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7baf6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://192.168.1.3:8501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Streamlit in the background  #\n",
    "#streamlit run rag_app1.py --logger.level=debug\n",
    "# ! streamlit run rag_app1.py & npx localtunnel --port 8500\n",
    "\n",
    "! streamlit run rag_app1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a32fd",
   "metadata": {},
   "source": [
    "## streamlit sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "28389f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_app.py\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Simple Test App\")\n",
    "st.write(\"If this works, then Streamlit is running properly\")\n",
    "name = st.text_input(\"Enter your name\")\n",
    "if name:\n",
    "    st.write(f\"Hello, {name}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b97eeca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run test_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3c60c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Run Streamlit in the background\n",
    "# ! streamlit run rag_app.py & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
