{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa1e8f5",
   "metadata": {},
   "source": [
    "## BERT Embeddings and NLP Applications\n",
    "\n",
    "\n",
    "In this notebook we will learn:\n",
    "\n",
    "- What BERT and BERT embeddings are  \n",
    "- Why contextual embeddings are better than static embeddings  \n",
    "- How to use BERT for:\n",
    "  - Text classification\n",
    "  - Named Entity Recognition (NER)\n",
    "  - Sentiment analysis\n",
    "\n",
    "We will use the Hugging Face `transformers` library and simple toy examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5b86d",
   "metadata": {},
   "source": [
    "## 1. BERT Embeddings\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) generates **context-aware embeddings**, meaning the same word gets different vectors based on context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch datasets sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbeb11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b207bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kumar\\.conda\\envs\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\kumar\\.conda\\envs\\langchain\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kumar\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/bert-base-uncased/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A70151E7A0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 19b08085-4e8c-4240-ab64-dadd8045314d)')' thrown while requesting GET https://huggingface.co/bert-base-uncased/resolve/main/model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A70151EFB0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 434ba44e-7d70-47a8-9952-986207e76b78)')' thrown while requesting GET https://huggingface.co/bert-base-uncased/resolve/main/model.safetensors\n",
      "Retrying in 2s [Retry 2/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text = \"I love machine learning\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(outputs.last_hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b652df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3472, -0.0077, -0.4201, -0.4972,  0.4066,  0.3982, -0.2802,  1.0115,\n",
      "        -0.0114, -0.6065], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Bank of the river\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state[0][1][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"Bank approved my loan\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state[0][1][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6270aa",
   "metadata": {},
   "source": [
    "## 2. Advantages over Static Embeddings\n",
    "\n",
    "Static embeddings like Word2Vec give **one vector per word**, but BERT gives **dynamic vectors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6cdc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = [\"He sat on the bank\", \"He went to the bank\"]\n",
    "for s in sentences:\n",
    "    inputs = tokenizer(s, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    print(outputs.last_hidden_state.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f24456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CLS token representation\n",
    "inputs = tokenizer(\"BERT is powerful\", return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "cls_embedding = outputs.last_hidden_state[:,0,:]\n",
    "print(cls_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e724bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sentence similarity idea\n",
    "import torch.nn.functional as F\n",
    "\n",
    "a = tokenizer(\"I love AI\", return_tensors='pt')\n",
    "b = tokenizer(\"I enjoy artificial intelligence\", return_tensors='pt')\n",
    "\n",
    "emb_a = model(**a).last_hidden_state.mean(dim=1)\n",
    "emb_b = model(**b).last_hidden_state.mean(dim=1)\n",
    "\n",
    "print(F.cosine_similarity(emb_a, emb_b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8c280",
   "metadata": {},
   "source": [
    "## 3. Text Classification\n",
    "\n",
    "Used for spam detection, topic classification, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80033f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\")\n",
    "classifier(\"I love this course\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb478f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier(\"This product is terrible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = [\"AI is amazing\", \"I hate bugs\"]\n",
    "classifier(texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755a204",
   "metadata": {},
   "source": [
    "## 4. Named Entity Recognition (NER)\n",
    "\n",
    "NER identifies entities like names, locations, organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"Google was founded in California\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383bcbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ner(\"Elon Musk is the CEO of Tesla\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbac69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ner(\"India won the match in Delhi\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e1b14",
   "metadata": {},
   "source": [
    "## 5. Sentiment Analysis\n",
    "\n",
    "Determines emotional tone of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a64ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentiment = pipeline(\"sentiment-analysis\")\n",
    "sentiment(\"I am very happy today\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentiment(\"This is the worst experience ever\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentiment([\"I love teaching\", \"I am tired today\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad61016",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- BERT uses bidirectional context\n",
    "- Better than Word2Vec/GloVe\n",
    "- Works well for classification, NER, sentiment\n",
    "- Widely used in real-world NLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
